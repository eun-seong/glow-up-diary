---
date: 2024-05-04
today:
---
## MySQL Bulk Insert

삽입해야 하는 데이터는 총 3,664,663 개.
360만 개를 어떻게 하면 효율적으로 넣을 수 있을까?
비교해보자.

### mysql.connector 모듈의 executemany()

**`reservation` table**
csv 파일을 읽어들이고 1000개씩 묶어서 삽입했다.
결과는 73.89067 sec

**`reservation2` table**
더 많이 묶어서 bulk insert 하면 더 빠를까 싶어서 10000개로 묶어서도 삽입해봤다.
오잉 근데 79.55183 sec 로 더 오래 걸렸다.

**`reservation3` table**
신기해서 100개씩 나눠서 실행해봤더니 237.96762 sec가 걸렸다.

| batch size(row) | time(sec) | count time(sec) |
| --------------- | --------- | --------------- |
| 100             | 237.96762 |                 |
| 1,000           | 73.89067  |                 |
| 10,000          | 79.55183  |                 |

결론은 많이 묶는다고 실행 속도가 빨라지는 것은 아니며, 환경에 따라 적정한 선을 찾아야 하는 듯 하다.

## 인덱스 키의 최대 크기

인덱스 생성하려고 했더니 아래 에러가 발생했다.

```
Specified key was too long; max key length is 3072 bytes
```

테스트한다고 생각없이 크게 잡아 놓은 크기 때문에 그렇다. 

컬럼의 특성에 맞게 크기를 재조정한 후 인덱스를 생성해주었다.


## 인덱스는 적절한 상황에서 사용해야지

**연령별 데이터 비율**

![](2024-05-04-20240504180618918.png)

### 전체 데이터 중 26% row를 모두 조회했을 때
여러 번 시도해봤는데 항상 인덱스를 사용하지 않은 경우가 더 빨랐다.

**인덱스를 사용한 경우가 아닌 경우보다 약 36% 느렸다.**


인덱스를 사용할 경우) 
![](2024-05-04-20240504180447546.png)


인덱스 사용하지 않을 경우)
![](2024-05-04-20240504180410412.png)



### 전체 데이터 중 11%에 해당하는 row를 모두 조회했을 때

더 빠를 거라 예상했지만, **의외로 결과는 비슷했다.**

인덱스를 사용할 경우)
![](2024-05-04-20240504180844837.png)

인덱스를 사용하지 않을 경우)
![](2024-05-04-20240504180812894.png)


### 전체 데이터 중 4%에 해당하는 row를 모두 조회했을 때

데이터 수가 작으니 확실히 차이가 났다. 
**인덱스를 사용한 경우가 아닌 경우보다 약 70% 빨랐다.**


인덱스를 사용한 경우)
![](2024-05-04-20240504181021160.png)

인덱스를 사용하지 않은 경우)
![](2024-05-04-20240504181044474.png)


## 그래서 결국 인덱스를 사용하지 않도록 수정하면

인덱스 사용할 때
![](2024-05-04-20240504190439378.png)


풀스캔할 때
![](2024-05-04-20240504190416905.png)

차이가 심하다! 
인덱스 사용할 때(3.662초)에서 풀스캔(1.502초)으로 변경하니 쿼리 시간이 143% 개선되었다.


4% 데이터 비율을 가지고 있는 데이터는 위에서 확인했던 것처럼 당연히 인덱스를 사용할 때가 훨씬 빨랐다.
![](2024-05-04-20240504190738212.png)

